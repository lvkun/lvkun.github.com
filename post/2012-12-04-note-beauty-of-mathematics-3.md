## 读书笔记 《数学之美》（三）

作者：吴军

### 拼音输入法

#### 拼音转汉字算法

每一个拼音可以对应多个汉字，把一个拼音串对应的汉字从左到右连起来，就是一张有向图，被称为网格图或者篱笆图（Lattice）。$y\_1,y\_2,y\_3,\cdots,y\_N$ 是使用者输入的拼音串； $w\_{i1},w\_{i2},\cdots,w\_{im}$ 是第 $i$ 个音 $y\_i$ 的候选汉字，是用 $w\_i$ 。从第一个字到最后一个字可以组成很多句子，每一个句子和图中的一条路径一一对应。拼音输入法就是要根据上下文在给定拼音条件下找到一个最优的句子，即：

$w\_1,w\_2,\cdots,w\_N = \underset{w \in W}{ArgMax}P(w\_1,w\_2,\cdots,w\_N|y\_1,y\_2,\cdots,y\_N) \approx \underset{w \in W}{ArgMax}\displaystyle\prod_t\_{i=1}^{N}P(w\_i|w\_{i-1}) \cdot P(y\_i|w\_i)$

如果对上面公式中的概率取对数并同时取反，即定义 $d(w\_{i-1},w\_i)=-logP(w\_i|w\_{i-1}) \cdot P(y\_i|w\_i)$ ，上面的连乘关系变成加法，寻找最大概率的问题就变成了寻找最短路径的问题。两个节点（词）$w\_{i-1}$ 和 $w\_i$ 之间的距离是转移概率和生成概率的乘积 $-logP(w\_i|w\_{i-1}) \cdot P(y\_i|w\_i)$ 。

#### 个性化的语言模型

1. 如何训练一个个性化的语言模型
   
   训练用户特定的语言模型步骤如下：
   
   1. 将训练语言模型的文本按照主题分成很多不同的类别，如：$C\_1,C\_2,\cdots,C\_N$
   2. 对每个类别，找到它们的特征向量（TF-IDF） $X\_1,X\_2,\cdots,X\_N$
   3. 统计某个人输入的文本，得到他输入的词的特征向量 $Y$
   4. 计算 $Y$ 和 $X\_1,X\_2,\cdots,X\_N$ 的余弦（距离）
   5. 选择前 $K$ 个和 $Y$ 距离最近的类对应的文本，作为这个特定用户语言模型的训练数据
   6. 训练一个用户特定的语言模型 $M\_1$

2. 如何处理好个性化语言模型 $M\_1$ 和通用语言模型 $M\_0$ 的关系

   假定 $M\_0$ 和 $M\_1$ 都是二元模型，它们计算出的 $(w\_{i-1},w\_{i})$ 的条件概率分别是 $P\_0(w\_i|w\_{i-1})$ 和 $P\_1(w\_i|w\_{i-1})$。新的模型为 $M'$ ，计算的条件概率应该是：

   $P'(w\_i|w\_{i-1})=\lambda(w\_{i-1}) \cdot P\_0(w\_i|w\_{i-1}) + (1-\lambda(w\_{i-1})) \cdot P\_1(w\_i|w\_{i-1})$
   
   其中 $0<\lambda(w\_{i-1})<1$ 是一个插值函数。

### 布隆过滤器

假定存储一亿个电子邮件地址，先建立一个16亿二进制（比特），即两亿字节的向量，然后将这16亿个二进制位全部清零。对于每一个电子邮件地址 $X$ ，用8个不同的随机数产生器（$F\_1,F\_2,\cdots,F\_8$）产生8个信息指纹（$f\_1,f\_2,\cdots,f\_8$），再用一个随机数产生器 $G$ 把这8个信息指纹映射到1-16亿中的8个自然数 $g\_1,g\_2,\cdots,g\_8$ ，把这8个位置的二进制都设置为1。对这一亿个电子邮件地址都进行这样处理。

如何用布隆过滤器来检测一个可疑的电子邮件地址 $Y$ 是否在黑名单中？

用相同的8个随机数产生器（$F\_1,F\_2,\cdots,F\_8$）对这个地址产生8个信息指纹（$s\_1,s\_2,\cdots,s\_8$），然后将这8个指纹对应到布隆过滤器的8个二进制位，分别是 $t\_1,t\_2,\cdots,t\_8$。如果 $Y$ 在黑名单中，$t\_1,t\_2,\cdots,t\_8$ 对应的8个二进制数一定是1。

布隆过滤器有极小可能将一个不在黑名单中的电子邮件地址也判定在黑名单中。

### 维特比算法

维特比算法是针对篱笆网络的有向图（Lattice）的最短路径问题而提出的。可以概括成以下三点：

1. 如果概率最大的路径 $P$ （或者说最短路径）经过某个点，比如 $x\_{ij}$ ，那么这条路径上从起始点 $S$ 到 $x\_{ij}$ 的这一段子路径 $Q$ ，一定是 $S$ 到 $x\_{ij}$ 之间的最短路径。否则，用 $S$ 到 $x\_{ij}$的最短路径代替 $Q$ ，便能构成一条比 $P$ 更短的路径，这显然是矛盾的。
2. 从 $S$ 到 $E$ 的路径必定经过第 $i$ 时刻的某个状态，假定第 $i$ 时刻有 $k$ 个状态，那么如果记录了从 $S$ 到第 $i$ 个状态的所有 $k$ 个节点的最短路径，最终的最短路径必经过其中一条。这样，在任何时刻，只要考虑非常有限条最短路径即可。
3. 结合上述两点，假定当我们从状态 $i$ 进入状态 $i+1$ 时，从 $S$ 到状态 $i$ 上各个节点的最短路径已经找到，并且记录在这些节点上，那么在计算从起点 $S$ 到第 $i+1$ 状态的某个节点 $x\_{i+1, j}$ 的最短路径时，只要考虑从 $S$ 到前一个状态 $i$ 所有的 $k$ 个节点的最短路径，以及从这 $k$ 个节点到 $x_{i+1,j}$的距离即可

算法总结如下：

第一步，从起点 $S$ 出发，对于第一个状态 $x\_1$ 的各个节点，假设有 $n\_1$ 个，计算出 $S$ 到它们的距离 $d(S, x\_{1i})$。因为只有一步，所以这些距离都是 $S$ 到它们各自的最短距离。

第二步，对于第二个状态 $x\_2$ 的所有节点，要计算出从 $S$ 到它们的最短距离。对于特定的节点 $x\_{2i}$，从 $S$ 到它的路径可以经过状态 $1$ 的 $n\_1$ 中任何一个节点 $x\_{1i}$，对应的路径长度是 $d(S, x\_{2i}) = d(S, x\_{1j}) + d(x\_{1j}, x\_{2i})$，取最小值，即：

$d(S, x\_{2i}) = min\_{j=1,n\_{1}}d(S, x\_{1j}) + d(x\_{1j}, x\_{2i})$

按照上述方法，一直计算到最后一个状态，就可以得到整个网格从头到尾的最短路径。每一步计算的复杂度都和相邻两个状态 $S\_i$ 和 $S\_{i+1}$ 各自的节点数目 $n\_{i}, n\_{i+1}$的乘积成正比，即 $O(n\_{i} \cdot n\_{i+1})$。如果假定节点最多的状态有 $D$ 个节点（网格宽度为 $D$ ），网格长度为 $N$ ，整个维特比算法的复杂度为 $O(N \cdot D^2)$。

### 后记

其他感兴趣的内容还包括“贝叶斯网络”，“条件随机场”，“期望最大化算法”。
